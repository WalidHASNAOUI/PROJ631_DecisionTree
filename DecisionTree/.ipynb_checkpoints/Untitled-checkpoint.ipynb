{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f17b58e1",
   "metadata": {},
   "source": [
    "## 1- Training Step "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be1df2",
   "metadata": {},
   "source": [
    "### Task 1 : `Read csv file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d464cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73ab5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/golf.csv\"\n",
    "data = pd.read_csv(file)\n",
    "# data.set_index('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2dca6fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook\n",
      "temp\n",
      "humidity\n",
      "wind\n",
      "play\n"
     ]
    }
   ],
   "source": [
    "# list all attributes \n",
    "for e in data.columns: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29b13b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     outlook  temp humidity   wind play\n",
      "0      sunny   hot     high  False   no\n",
      "1      sunny   hot     high   True   no\n",
      "2   overcast   hot     high  False  yes\n",
      "3       rain  mild     high  False  yes\n",
      "4       rain  cool   normal  False  yes\n",
      "5       rain  cool   normal   True   no\n",
      "6   overcast  cool   normal   True  yes\n",
      "7      sunny  mild     high  False   no\n",
      "8      sunny  cool   normal  False  yes\n",
      "9       rain  mild   normal  False  yes\n",
      "10     sunny  mild   normal   True  yes\n",
      "11  overcast  mild     high   True  yes\n",
      "12  overcast   hot   normal  False  yes\n",
      "13      rain  mild     high   True   no\n"
     ]
    }
   ],
   "source": [
    "# list values \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c2c3f",
   "metadata": {},
   "source": [
    "### Task 2 :`Construction of Id3 Tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "02f5fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Entropy function \n",
    "def calc_entropy(my_target):\n",
    "    # Count the occurrences of each unique value in the target column\n",
    "    value_counts = my_target.value_counts()\n",
    "    \n",
    "    # Calculate the probabilities of each unique value\n",
    "    probabilities = value_counts / len(my_target)\n",
    "    \n",
    "    # Calculate entropy using the formula: -sum(p * log2(p))\n",
    "    entropy_val = -sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    return entropy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "34b8e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the information_gain function \n",
    "def calc_information_gain(data, split_attribute_name, target_name):\n",
    "    # Calculate the entropy of the entire dataset based on the target variable\n",
    "    total_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    # Calculate the probabilities of each unique value of the split attribute\n",
    "    unique_values, value_counts = np.unique(data[split_attribute_name], return_counts=True)\n",
    "    probabilities = value_counts / len(data)\n",
    "    \n",
    "    # Calculate the weighted average entropy after splitting on each unique value of the split attribute\n",
    "    weighted_entropies = []\n",
    "    for value in unique_values:\n",
    "        subset = data[data[split_attribute_name] == value]\n",
    "        subset_entropy = calc_entropy(subset[target_name])\n",
    "        weighted_entropies.append((len(subset) / len(data)) * subset_entropy)\n",
    "    \n",
    "    weighted_entropy = sum(weighted_entropies)\n",
    "    \n",
    "    # Step 4: Calculate the information gain\n",
    "    info_gain_val = total_entropy - weighted_entropy\n",
    "    \n",
    "    return info_gain_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "17c8f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(data, features, target_name):\n",
    "    # Calculate information gain for each feature\n",
    "    info_gain_values = [calc_information_gain(data, feature, target_name) for feature in features]\n",
    "    \n",
    "    # Find the index of the feature with the highest information gain\n",
    "    best_feature_index = np.argmax(info_gain_values)\n",
    "    \n",
    "    # Get the best feature based on the index\n",
    "    best_feature = features[best_feature_index]\n",
    "    \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "37f2b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_attribute_name):\n",
    "    unique_values = data[split_attribute_name].unique()\n",
    "    subdatasets = {value: data[data[split_attribute_name] == value].dropna() for value in unique_values}\n",
    "    return subdatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "45a609b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data, features, target_name):\n",
    "    unique_classes, counts = np.unique(data[target_name], return_counts=True)\n",
    "    \n",
    "    # If all instances belong to the same class\n",
    "    if len(unique_classes) == 1:\n",
    "        return unique_classes[0]\n",
    "    \n",
    "    # If there are no more features to split on\n",
    "    if len(features) == 0:\n",
    "        return unique_classes[np.argmax(counts)]\n",
    "    \n",
    "    # Determine the best feature to split on\n",
    "    best_feature = best_split(data, features, target_name)\n",
    "    tree = {best_feature: {}}\n",
    "    \n",
    "    # Remove the best feature from the list of features\n",
    "    remaining_features = [feature for feature in features if feature != best_feature]\n",
    "    \n",
    "    # Recursively build the tree for each split value\n",
    "    for value, subdata in split_data(data, best_feature).items():\n",
    "        tree[best_feature][value] = build_tree(subdata, remaining_features, target_name)\n",
    "        \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "042f7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query, tree):\n",
    "    # Loop through each key in the query dictionary\n",
    "    for key in query.keys():\n",
    "        \n",
    "        # Check if the key exists in the decision tree\n",
    "        if key in tree:\n",
    "            \n",
    "            # Get the result based on the query value for the current key\n",
    "            result = tree[key][query[key]]\n",
    "            \n",
    "            # If the result is another dictionary, recursively call predict\n",
    "            if isinstance(result, dict):\n",
    "                return predict(query, result)\n",
    "            \n",
    "            # If the result is a final outcome, return it\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5dab44",
   "metadata": {},
   "source": [
    "### Task 4 : `Displaying the ID3 Tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "47aa46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function in order ot convert all ID3 tree keys to strings \n",
    "def convert_keys_to_strings(dictionary):\n",
    "    new_dict = {}\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        # Convert numpy bool to Python bool\n",
    "        if isinstance(key, np.bool_):\n",
    "            key = bool(key)\n",
    "        \n",
    "        # Convert numpy generic type to scalar\n",
    "        if isinstance(key, np.generic):\n",
    "            key = np.asscalar(key)\n",
    "        \n",
    "        # Recursively convert nested dictionaries\n",
    "        if isinstance(value, dict):\n",
    "            new_dict[str(key)] = convert_keys_to_strings(value)\n",
    "        else:\n",
    "            new_dict[str(key)] = value\n",
    "    \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f425332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"outlook\": {\n",
      "        \"sunny\": {\n",
      "            \"humidity\": {\n",
      "                \"high\": \"no\",\n",
      "                \"normal\": \"yes\"\n",
      "            }\n",
      "        },\n",
      "        \"overcast\": \"yes\",\n",
      "        \"rain\": {\n",
      "            \"wind\": {\n",
      "                \"False\": \"yes\",\n",
      "                \"True\": \"no\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get features and target name\n",
    "features = data.columns.tolist()[:-1]  # Assuming the last column is the target\n",
    "target_name = data.columns.tolist()[-1]\n",
    "\n",
    "# Build the ID3 tree\n",
    "tree = build_tree(data, features, target_name)\n",
    "\n",
    "# Save the ID3 tree as json file\n",
    "with open(\"sample.json\", \"w\") as outfile: \n",
    "    json.dump(convert_keys_to_strings(tree), outfile)\n",
    "\n",
    "# # Print the ID3 tree \n",
    "print(json.dumps(convert_keys_to_strings(tree), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(tree, parent_name, level=0):\n",
    "    for key, value in tree.items():\n",
    "        if isinstance(value, dict):\n",
    "            plt.scatter(level, 0, color='g')\n",
    "            plt.text(level, 0, key)\n",
    "            plot_tree(value, key, level + 1)\n",
    "        else:\n",
    "            plt.scatter(level, 0, color='r' if value == 'yes' else 'b')\n",
    "            plt.text(level, 0, f\"{key}: {value}\", color='r' if value == 'yes' else 'b')\n",
    "            plt.plot([level, parent_name], [0, -1], color='k')\n",
    "            \n",
    "plt.figure(figsize=(10, 5))\n",
    "plot_tree(tree, parent_name='Root')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbbde8",
   "metadata": {},
   "source": [
    "### Task 4 : `Define the Confusion Matrix denoted as m_app`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "32755b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions based of S_app: \n",
      "0      no\n",
      "1      no\n",
      "2     yes\n",
      "3     yes\n",
      "4     yes\n",
      "5      no\n",
      "6     yes\n",
      "7      no\n",
      "8     yes\n",
      "9     yes\n",
      "10    yes\n",
      "11    yes\n",
      "12    yes\n",
      "13     no\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Confusion Matrix for Training (m_app):\n",
      " [[9 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "def compute_confusion_matrix(data, tree, target_name):\n",
    "    # Initialize the confusion matrix\n",
    "    tp = tn = fp = fn = 0\n",
    "    \n",
    "    # Make predictions using the tree\n",
    "    predictions = data.apply(lambda row: predict(row, tree), axis=1)\n",
    "    print(\"predictions based of S_app: \")\n",
    "    print(predictions)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Compare predictions with actual labels to populate the confusion matrix\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == data.iloc[i][target_name]:\n",
    "            if predictions[i] == \"yes\":\n",
    "                tp += 1  # True Positive\n",
    "            else:\n",
    "                tn += 1  # True Negative\n",
    "        else:\n",
    "            if predictions[i] == \"yes\":\n",
    "                fp += 1  # False Positive\n",
    "            else:\n",
    "                fn += 1  # False Negative\n",
    "    \n",
    "    # Create the confusion matrix\n",
    "    m_app = np.array([[tp, fp], [fn, tn]])\n",
    "    \n",
    "    return m_app\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'data' is your training dataset and 'tree' is your constructed ID3 decision tree\n",
    "m_app = compute_confusion_matrix(data, tree, target_name)\n",
    "\n",
    "print(\"Confusion Matrix for Training (m_app):\\n\", m_app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844d875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7230ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
